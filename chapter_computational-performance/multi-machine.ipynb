{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Machine Training\n",
    "\n",
    "Distributed training on multiple machines adds a further challenge: we need to communicate with servers that are only connected across a comparatively lower bandwidth fabric which can be over an order of magnitude slower in some cases. Synchronization across devices is tricky. After all, different machines running training code will have subtly different speed. Hence we need to *synchronize* them if we want to use synchronous distributed optimization. :numref:`fig_ps_multimachine` illustrates how distributed parallel training occurs.\n",
    "\n",
    "\n",
    "![Multi-machine multi-GPU distributed parallel training.](../img/ps-multimachine.svg)\n",
    ":label:`fig_ps_multimachine`\n",
    "\n",
    "\n",
    "1. A (different) batch of data is read on each machine, split across multiple GPUs and transferred to GPU memory. Their predictions and gradients are computed on each GPU batch separately.\n",
    "2. The gradients from all local GPUs are aggregated on one GPU (or alternatively parts of it are aggregated over different GPUs.\n",
    "3. The gradients are sent to the CPU.\n",
    "4. The CPU sends the gradients to a central parameter server which aggregates all the gradients.\n",
    "5. The aggregate gradients are then used to update the weight vectors and the updated weight vectors are broadcast back to the individual CPUs.\n",
    "6. The information is sent to one (or multiple) GPUs.\n",
    "7. The updated weight vectors are spread across all GPUs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Each of these operations seems rather straightforward. And, indeed, they can be carried out efficiently *within* a single machine. Once we look at multiple machines, though, we can see that the central parameter server becomes the bottleneck. After all, the bandwidth per server is limited, hence for $m$ workers the time it takes to send all gradients to the server is $O(m)$. We can break through this barrier by increasing the number of servers to $n$. At this point each server only needs to store $O(1/n)$ of the parameters, hence the total time for updates and optimization becomes $O(m/n)$. Matching both numbers yields constant scaling regardless of how many workers we are dealing with. In practice we use the *same* machines both as workers and as servers. :numref:`fig_ps_multips` illustrates the design. See also :cite:`Li.Andersen.Park.ea.2014` for details. In particular, ensuring that multiple machines work without unreasonable delays is nontrivial. We omit details on barriers and will only briefly touch on synchronous and asynchronous updates below. \n",
    "\n",
    "![Top - a single parameter server is a bottleneck since its bandwidth is finite. Bottom - multiple parameter servers store parts of the parameters with aggregate bandwidth.](../img/ps-multips.svg)\n",
    ":label:`fig_ps_multips`\n",
    "\n",
    "\n",
    "\n",
    "Let's implement the above 7 operations in python. Here we will show an example of distributed training a ResNet18 network over two machines. As you may notice in the below code, rather than executing each code block in this jupyter notebook, we are writting the functions and parameters to a file named \"multimachine_cifar10_train.py\". This python script will be called later by another executor \"launcher.py\", which supports the multi-machine training flows.\n",
    "\n",
    "\n",
    "Now, let's dive into each steps. First, importing all supported packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting multimachine_cifar10_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multimachine_cifar10_train.py\n",
    "from __future__ import print_function\n",
    "import collections, math, os, random, shutil, sys, time\n",
    "import d2l\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, kv, init, np, npx\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "npx.set_np()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training will be relatively similar to :ref:`sec_kaggle_cifar10` in terms of the dataset and neural net architecture. Let's load and reorganize the dataset, which a small subset of CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to multimachine_cifar10_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a multimachine_cifar10_train.py\n",
    "\n",
    "d2l.DATA_HUB['cifar10_tiny'] = (d2l.DATA_URL + 'kaggle_cifar10_tiny.zip',\n",
    "                                '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')\n",
    "data_dir = d2l.download_extract('cifar10_tiny')\n",
    "train_data_size = 800\n",
    "batch_size = 1\n",
    "\n",
    "def reorg_cifar10_data(data_dir, valid_ratio):\n",
    "    labels = d2l.read_csv_labels(data_dir + 'trainLabels.csv')\n",
    "    d2l.reorg_train_valid(data_dir, labels, valid_ratio)\n",
    "    d2l.reorg_test(data_dir)\n",
    "\n",
    "reorg_cifar10_data(data_dir, valid_ratio = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a key-value store for distributed training on multiple machines with the keyword \"dist\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to multimachine_cifar10_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a multimachine_cifar10_train.py\n",
    "\n",
    "store = kv.create('dist')\n",
    "# print(\"Total number of workers: %d\" % store.num_workers)\n",
    "# print(\"This worker's rank: %d\" % store.rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to multimachine_cifar10_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a multimachine_cifar10_train.py\n",
    "\n",
    "## Step 1: Define how to split a batch for multimachine training\n",
    "class SplitBatchSampler(gluon.data.sampler.Sampler):\n",
    "    \n",
    "    def __init__(self, length, batch_size, num_parts=1, part_index=0, last_batch='keep'):\n",
    "        self.part_len = length // num_parts\n",
    "        self._batch_size = batch_size\n",
    "        self.start = self.part_len * part_index\n",
    "        self.end = self.start + self.part_len\n",
    "        self._last_batch = last_batch\n",
    "        self._prev = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = list(range(self.start, self.end))\n",
    "        random.shuffle(indices)\n",
    "        batch, self._prev = self._prev, []\n",
    "        for i in indices:\n",
    "            batch.append(i)\n",
    "            if len(batch) == self._batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        if batch:\n",
    "            if self._last_batch == 'keep':\n",
    "                yield batch\n",
    "            elif self._last_batch == 'discard':\n",
    "                return\n",
    "            elif self._last_batch == 'rollover':\n",
    "                self._prev = batch\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"last_batch must be one of 'keep', 'discard', or 'rollover', \" \\\n",
    "                    \"but got %s\"%self._last_batch)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self._last_batch == 'keep':\n",
    "            return (len(self._sampler) + self._batch_size - 1) // self._batch_size\n",
    "        if self._last_batch == 'discard':\n",
    "            return len(self._sampler) // self._batch_size\n",
    "        if self._last_batch == 'rollover':\n",
    "            return (len(self._prev) + len(self._sampler)) // self._batch_size\n",
    "        raise ValueError(\n",
    "            \"last_batch must be one of 'keep', 'discard', or 'rollover', \" \\\n",
    "            \"but got %s\"%self._last_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to multimachine_cifar10_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a multimachine_cifar10_train.py\n",
    "\n",
    "## Step 2: Create and build the training/test dataset\n",
    "\n",
    "# Load the training and test data\n",
    "transform_train = gluon.data.vision.transforms.Compose([\n",
    "    # Magnify the image to a square of 40 pixels in both height and width\n",
    "    gluon.data.vision.transforms.Resize(40),\n",
    "    # Randomly crop a square image of 40 pixels in both height and width to\n",
    "    # produce a small square of 0.64 to 1 times the area of the original\n",
    "    # image, and then shrink it to a square of 32 pixels in both height and\n",
    "    # width\n",
    "    gluon.data.vision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),\n",
    "                                                   ratio=(1.0, 1.0)),\n",
    "    gluon.data.vision.transforms.RandomFlipLeftRight(),\n",
    "    gluon.data.vision.transforms.ToTensor(),\n",
    "    # Normalize each channel of the image\n",
    "    gluon.data.vision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                           [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "transform_test = gluon.data.vision.transforms.Compose([\n",
    "    gluon.data.vision.transforms.ToTensor(),\n",
    "    gluon.data.vision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                           [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "train_ds, test_ds = [\n",
    "    gluon.data.vision.ImageFolderDataset(data_dir + \"train_valid_test/\" + folder)\n",
    "    for folder in ['train','test']]\n",
    "\n",
    "train_iter = gluon.data.DataLoader(\n",
    "    train_ds.transform_first(transform_train), \n",
    "    batch_sampler=SplitBatchSampler(train_data_size, batch_size, store.num_workers, store.rank, last_batch='keep'),\n",
    ") \n",
    "\n",
    "test_iter = gluon.data.DataLoader(\n",
    "    test_ds.transform_first(transform_test), batch_size, shuffle=False,\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to multimachine_cifar10_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a multimachine_cifar10_train.py\n",
    "\n",
    "## Step 3: Define and initial Resnet\n",
    "class Residual(nn.HybridBlock):\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1,\n",
    "                               strides=strides)\n",
    "        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2D(num_channels, kernel_size=1,\n",
    "                                   strides=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm()\n",
    "        self.bn2 = nn.BatchNorm()\n",
    "\n",
    "    def hybrid_forward(self, F, X):\n",
    "        Y = F.npx.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return F.npx.relu(Y + X)\n",
    "    \n",
    "def resnet18(num_classes):\n",
    "    net = nn.HybridSequential()\n",
    "    net.add(nn.Conv2D(64, kernel_size=3, strides=1, padding=1),\n",
    "            nn.BatchNorm(), nn.Activation('relu'))\n",
    "\n",
    "    def resnet_block(num_channels, num_residuals, first_block=False):\n",
    "        blk = nn.HybridSequential()\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.add(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.add(Residual(num_channels))\n",
    "        return blk\n",
    "\n",
    "    net.add(resnet_block(64, 2, first_block=True),\n",
    "            resnet_block(128, 2),\n",
    "            resnet_block(256, 2),\n",
    "            resnet_block(512, 2))\n",
    "    net.add(nn.GlobalAvgPool2D(), nn.Dense(num_classes))\n",
    "    return net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to multimachine_cifar10_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a multimachine_cifar10_train.py\n",
    "\n",
    "## Step 4: Define the training function\n",
    "def train(net, train_iter, test_iter, num_epochs, lr, wd, ctx, lr_period,\n",
    "          lr_decay):\n",
    "\n",
    "    # Use SGD optimizer. Ask trainer to use the distributor kv store.\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', \n",
    "                            {'learning_rate': lr, 'momentum': 0.9, 'wd': wd}, \n",
    "                            kvstore=store)\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        if epoch > 0 and epoch % lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for X, y in train_iter:\n",
    "            y = y.astype('float32').as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X.as_in_context(ctx))\n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l_sum += float(l)\n",
    "            train_acc_sum += float((y_hat.argmax(axis=1) == y).sum())\n",
    "            n += y.size\n",
    "        time_s = \"time %.2f sec\" % (time.time() - start)\n",
    "#         if valid_iter is not None:\n",
    "#             valid_acc = d2l.evaluate_accuracy_gpu(net, valid_iter)\n",
    "#             epoch_s = (\"epoch %d, loss %f, train acc %f, valid acc %f, \"\n",
    "#                        % (epoch + 1, train_l_sum / n, train_acc_sum / n,\n",
    "#                           valid_acc))\n",
    "#         else:\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        epoch_s = (\"epoch %d, loss %f, train acc %f, test acc %f\" %\n",
    "                   (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "        print(epoch_s + time_s + ', lr ' + str(trainer.learning_rate))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser(description='Launch a distributed job')\n",
    "#     parser.add_argument('-e', '--num_epochs', required=True, type=int,\n",
    "#                         help = 'number of epochs to train')\n",
    "#     parser.add_argument('-lr', '--learning_rate', required=True, type=float,\n",
    "#                         help = 'learning rate control how much an updating step influences \\\n",
    "#                         the current value of the weights')\n",
    "#     parser.add_argument('-wd', '--weight_decay', type=float,\n",
    "#                         help = 'weight decay adds a penalty term to the loss function \\\n",
    "#                         to reduce the complexity of the learned model (weights)')\n",
    "#     parser.add_argument('--lr_decay', default=0.1, type=float,\n",
    "#                         help = 'The scope of learning rate decay at a learning rate peroid')\n",
    "#     parser.add_argument('--lr_period', default=80, type=int,\n",
    "#                         help = 'The frequency that the learning rate will decay with \\\n",
    "#                         a scope of lr_decay')\n",
    "#     train(net, train_iter, test_iter, num_epochs, lr, wd, ctx, lr_period, lr_decay)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to multimachine_cifar10_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a multimachine_cifar10_train.py\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ctx = d2l.try_gpu()\n",
    "    num_epochs, lr, wd = 1, 0.1, 5e-4\n",
    "    lr_period, lr_decay  = 80, 0.1\n",
    "\n",
    "    num_classes = 10\n",
    "    net = resnet18(num_classes)\n",
    "    net.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "    net.hybridize()\n",
    "    train(net, train_iter, test_iter, num_epochs, lr, wd, ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:10:09] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "[23:10:09] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "epoch 1, loss 8815.827673, train acc 0.120000, test acc 0.000000time 38.27 sec, lr 0.1\n",
      "epoch 1, loss 5286.654214, train acc 0.127500, test acc 0.000000time 38.20 sec, lr 0.1\n",
      "terminate called without an active exception\n",
      "terminate called without an active exception\n",
      "^C\n",
      "2020-02-09 23:11:04,860 INFO Stop launcher\n"
     ]
    }
   ],
   "source": [
    "launcher_path = \"/home/ubuntu/miniconda3/envs/d2l/lib/python3.7/site-packages/mxnet/tools/launch.py\"\n",
    "current_dir = !pwd\n",
    "\n",
    "\n",
    "!python {launcher_path} \\\n",
    "    -n 2 -s 2 \\\n",
    "    --sync-dst-dir {current_dir} \\\n",
    "    --launcher local \"python multimachine_cifar10_train.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
